{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation of Datasets\n",
    "Datasets need to be first downloaded and copied in the folder \"raw_data\". The process is explained below for every single dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation of BeRfiPl Dataset\n",
    "Please first download the datasets from the simulation ds1 at https://drive.google.com/drive/folders/1JJ80uSWyBDHvwBgc2UcIOlMgUsk7YhWt and save them in the folder raw_data/BeRfiPl/. <br>\n",
    "Done this, please execute the following lines of code. <br>\n",
    "The Code will save the preprocessed file in the directory preprocessed_data/BeRfiPl/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation of SmA Dataset\n",
    "Please first download the dataset from https://github.com/thomasbierweiler/FaultsOf4-TankBatchProcess/blob/main/SmA-Four-Tank-Batch-Process_V2.zip and save them in the folder raw_data/SmA/. <br>\n",
    "Done this, please execute the following lines of code. <br>\n",
    "The Code will save the preprocessed files the directory preprocessed_data/SmA/.  <br>\n",
    "The first file will be exclusively from Deviation ID1. <br>\n",
    "The following files are a merged combination of ID1 (nominal behavior) and a anomaly Deviation ID (ID2 - ID10).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "!pip install openpyxl\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_SmA(raw_data_path, preprocessed_data_path):\n",
    "    df = pd.read_csv(raw_data_path, delimiter=';', index_col=0)\n",
    "    df_norm =  df.loc[df[df.columns[0]] == 1].reset_index(drop=True).drop(columns=['DeviationID ValueY'])\n",
    "    df_norm.to_csv(f'{preprocessed_data_path}id1_norm.csv', index=False)\n",
    "    for i in range(9):\n",
    "        df_anomaly = df.loc[df[df.columns[0]] == i+2].reset_index(drop=True).drop(columns=['DeviationID ValueY'])\n",
    "        df_preprocessed = pd.concat([df_norm, df_anomaly])\n",
    "        df_preprocessed.to_csv(f'{preprocessed_data_path}id{i+2}_anomaly.csv', index=False)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SmA_raw_data_path = 'raw_data/SmA/SmA-Four-Tank-Batch-Process_V2.csv'\n",
    "SmA_data_path = 'preprocessed_data/SmA/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_SmA(SmA_raw_data_path, SmA_data_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
