{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import json\n",
    "import yaml\n",
    "import numpy as np\n",
    "from aalpy.learning_algs import run_Alergia\n",
    "from aalpy.utils import visualize_automaton\n",
    "\n",
    "from seqcat_datamodule import Dataset\n",
    "from seqcat_catvae import seqcat_vae\n",
    "from seq_vae import seq_vae\n",
    "from discret2dive import check_normal\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "np.random.seed(123)\n",
    "torch.manual_seed(123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_transitions(idx):\n",
    "    # load trained model\n",
    "    MODEL_VERSION = f'VAE_training_hparams/tank_discret2deepdive'\n",
    "    ckpt_file_name = os.listdir(f'./{MODEL_VERSION}/checkpoints/')[-1]\n",
    "    ckpt_file_path = f'./{MODEL_VERSION}/checkpoints/{ckpt_file_name}'\n",
    "    with open(f'./{MODEL_VERSION}/hparams.yaml') as f:\n",
    "        hparam = yaml.safe_load(f)\n",
    "    model = seqcat_vae.load_from_checkpoint(ckpt_file_path, hparams=hparam[\"hparams\"])\n",
    "\n",
    "    MODEL_VERSION_SEQ = 'VAE_training_hparams/tank/seq_vae'\n",
    "    threshold = -170\n",
    "    ckpt_file_name_seq = os.listdir(f'./{MODEL_VERSION_SEQ}/checkpoints/')[-1]\n",
    "    ckpt_file_path_seq = f'./{MODEL_VERSION_SEQ}/checkpoints/{ckpt_file_name_seq}'\n",
    "    with open(f'./{MODEL_VERSION_SEQ}/hparams.yaml') as f:\n",
    "        hparam_seq = yaml.safe_load(f)\n",
    "    model_seq = seq_vae.load_from_checkpoint(checkpoint_path=ckpt_file_path_seq, hparams = hparam_seq)\n",
    "    \n",
    "    # read normal data\n",
    "    df_csv = pd.read_csv(f'preprocessed_data/tank_simulation/norm_long.csv').iloc[:, :3].reset_index(drop=True)\n",
    "    df_csv_realcat = pd.read_csv(f'preprocessed_data/tank_simulation/norm_long.csv').reset_index(drop=True).iloc[:2000, 3].reset_index(drop=True)\n",
    "    scaler = StandardScaler().fit(pd.read_csv('preprocessed_data/tank_simulation/norm_long.csv').iloc[:, :3].reset_index(drop=True))\n",
    "    df_csv_sc = pd.DataFrame(scaler.transform(df_csv), columns=df_csv.columns, index=df_csv.index).iloc[:2000, :].reset_index(drop=True)\n",
    "    faulty_idx = df_csv_realcat.str.contains('faulty').astype(int)\n",
    "    dataset = Dataset(dataframe=df_csv_sc.iloc[:, :3].reset_index(drop=True), number_timesteps=hparam[\"hparams\"][\"NUMBER_TIMESTEPS\"])\n",
    "\n",
    "\n",
    "    all_cats = []\n",
    "    all_kl = []\n",
    "    all_mu = []\n",
    "    # compute discretized categories and likelihoods\n",
    "    for window in dataset:\n",
    "        pzx_logits, pzx, mu, sigma, pxz, z = model.get_states(window.unsqueeze(0).to('cuda'))\n",
    "        _, kl = model.kl_divergence(pzx=pzx)\n",
    "        z_list = z.detach().cpu().numpy().astype(int) \n",
    "        all_cats.append(z_list)\n",
    "        all_kl.append(kl.detach().cpu().numpy())\n",
    "        all_mu.append(mu.detach().cpu().numpy())\n",
    "\n",
    "    all = pd.DataFrame(np.vstack(all_cats))\n",
    "    cats = pd.DataFrame(all.idxmax(axis=1))\n",
    "    # detect whether the category changes or not\n",
    "    cats['Prev_Value'] = cats[cats.columns[0]].shift(1)\n",
    "    cats['Change'] = (cats[cats.columns[0]] != cats['Prev_Value'])\n",
    "    transitions = cats[cats['Change'] == True]\n",
    "    transitions = transitions.dropna()\n",
    "    return transitions\n",
    "\n",
    "def learn_automata(transitions):\n",
    "    # learning an automata based on Alergia library\n",
    "    model = run_Alergia(data=[transitions[transitions.columns[0]].to_list()], automaton_type='mc', eps=0.001, print_info=True)\n",
    "    transitions_data = []  # List to collect transition data\n",
    "    for state in model.states:\n",
    "        for sub in state.transitions: \n",
    "            transition = {\n",
    "                'Previous': state.output,\n",
    "                'Current': sub[0].output,\n",
    "                'Probability': sub[1]\n",
    "            }\n",
    "            transitions_data.append(transition)\n",
    "    transitions_df = pd.DataFrame(transitions_data)\n",
    "    transitions_df.to_csv('preprocessed_data/tank_transitions.csv')\n",
    "    \n",
    "    automaton = {}\n",
    "    for index, row in transitions_df.iterrows():\n",
    "        prev = str(int(row['Previous'])) \n",
    "        curr = str(int(row['Current']))\n",
    "        prob = row['Probability']\n",
    "\n",
    "        if prev not in automaton:\n",
    "            automaton[prev] = {}\n",
    "        automaton[prev][curr] = prob\n",
    "\n",
    "    with open('preprocessed_data/automaton.json', 'w') as json_file:\n",
    "        json.dump(automaton, json_file, indent=4)\n",
    "\n",
    "def rule_learning():\n",
    "    # min threshold for applicable rules \n",
    "    min_threshold = 0.0005\n",
    "    # factor of support for association rule mining\n",
    "    min_support = 0.0002\n",
    "    # likelihood threshold for anomaly detection\n",
    "    threshold_likelihood = -50\n",
    "    # paths to save for learned rules\n",
    "    dict_path = 'tank_dict_states_char'\n",
    "    rule_path = 'tank_rule'\n",
    "    anomaly_df, likelihood, threshold_res = check_normal(min_support, dict_path, rule_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning diagnosis rules based on the catvae discretization\n",
    "rule_learning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# computation of transitions based on catvae and normal data\n",
    "transitions = compute_transitions(idx=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning an automata and save the information. \n",
    "learn_automata(transitions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "improved_discret2di",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
